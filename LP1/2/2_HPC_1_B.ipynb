{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDXz24mtLpDP",
        "outputId": "3442b2c7-4c96-4fff-8612-fd0415432b6a"
      },
      "outputs": [],
      "source": [
        "!apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "!dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "!apt-get remove cuda-*\n",
        "!apt autoremove\n",
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eagixUVOLqeH",
        "outputId": "dd6fe34f-7e57-4d25-9fde-70647d641305"
      },
      "outputs": [],
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda-9.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32CtA7LRoI_5",
        "outputId": "c969d0e7-ab46-40a2-82ee-fb600a97fe38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Wed_Apr_11_23:16:29_CDT_2018\n",
            "Cuda compilation tools, release 9.2, V9.2.88\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk9G517QqXYF",
        "outputId": "eb0654ef-c2c4-424c-c038-c451d6d4a62d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-qsy2u0t1\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-qsy2u0t1\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4305 sha256=b35e59df6dd39e1284169bbdb959e99d23802e34cd30fb4f0bb5178528465ca0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8u46o_2y/wheels/c5/2b/c0/87008e795a14bbcdfc7c846a00d06981916331eb980b6c8bdf\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iruGcr2pqdw-",
        "outputId": "901e0090-6c68-439e-8663-3b73e2bb3b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWRRww0nqrbu",
        "outputId": "3e9a9baa-c9af-45b4-d578-39ba3edd5105"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of elements: 100\n",
            "383 886 777 915 793 335 386 492 649 421 362 27 690 59 763 926 540 426 172 736 211 368 567 429 782 530 862 123 67 135 929 802 22 58 69 167 393 456 11 42 229 373 421 919 784 537 198 324 315 370 413 526 91 980 956 873 862 170 996 281 305 925 84 327 336 505 846 729 313 857 124 895 582 545 814 367 434 364 43 750 87 808 276 178 788 584 403 651 754 399 932 60 676 368 739 12 226 586 94 539 \n",
            "\n",
            "The maximum element is 996\n",
            "The minimum element is 11\n",
            "The sum of elements is 30020\n",
            "The average of elements is 135.267\n",
            "The standard deviation of elements is 360.669\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "using namespace std;\n",
        "\n",
        "__global__ void max(float *input)\n",
        "{\n",
        "    int tid = threadIdx.x;\n",
        "    auto step = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "\n",
        "    while (number_of_threads > 0)\n",
        "    {\n",
        "        if (tid < number_of_threads)\n",
        "        {\n",
        "            int first = tid * step * 2;\n",
        "            int second = first + step;\n",
        "            if (input[second] > input[first])\n",
        "                input[first] = input[second];\n",
        "        }\n",
        "        step *= 2;\n",
        "        number_of_threads /= 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void min(float *input)\n",
        "{\n",
        "    int thread_id = threadIdx.x;\n",
        "    auto step = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "    while (number_of_threads > 0)\n",
        "    {\n",
        "        if (thread_id < number_of_threads)\n",
        "        {\n",
        "            int first = thread_id * step * 2;\n",
        "            int second = first + step;\n",
        "            if (input[second] < input[first])\n",
        "                input[first] = input[second];\n",
        "        }\n",
        "        step = step * 2;\n",
        "        number_of_threads /= 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void sum(float *input)\n",
        "{\n",
        "    int tid = threadIdx.x;\n",
        "    auto step = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "    while (number_of_threads > 0)\n",
        "    {\n",
        "        if (tid < number_of_threads)\n",
        "        {\n",
        "            int first = tid * step * 2;\n",
        "            int second = first + step;\n",
        "            input[first] = input[first] + input[second];\n",
        "        }\n",
        "        step = step * 2;\n",
        "        ;\n",
        "        number_of_threads = number_of_threads / 2;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void avg(float *input)\n",
        "{\n",
        "    const int tid = threadIdx.x;\n",
        "    auto step = 1;\n",
        "    int number_of_threads = blockDim.x;\n",
        "    int totalElements = number_of_threads * 2;\n",
        "    while (number_of_threads > 0)\n",
        "    {\n",
        "        if (tid < number_of_threads)\n",
        "        {\n",
        "            const int first = tid * step * 2;\n",
        "            const int second = first + step;\n",
        "            input[first] = input[first] + input[second];\n",
        "        }\n",
        "        step = step * 2;\n",
        "        ;\n",
        "        number_of_threads = number_of_threads / 2;\n",
        "    }\n",
        "    input[0] = input[0] / totalElements;\n",
        "}\n",
        "\n",
        "__global__ void mean_diff_sq(float *input, float mean)\n",
        "{\n",
        "    input[threadIdx.x] = input[threadIdx.x] - mean;\n",
        "    input[threadIdx.x] = input[threadIdx.x] * input[threadIdx.x];\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "    //Creating an array arr of size 100 with random numbers\n",
        "    int n = 100;\n",
        "    float *arr = new float[n];\n",
        "    int size = n * sizeof(float);\n",
        "    cout << \"Number of elements: \" << n << endl;\n",
        "    for (int i = 0; i < n; i++)\n",
        "    {\n",
        "        arr[i] = rand() % 1000;\n",
        "        cout << arr[i] << \" \";\n",
        "    }\n",
        "    cout << endl;\n",
        "\n",
        "    //Calculating maximum number in array arr\n",
        "    float *arr_max, result_max;\n",
        "    cudaMalloc(&arr_max, size);\n",
        "    cudaMemcpy(arr_max, arr, size, cudaMemcpyHostToDevice);\n",
        "    //Launch max kernel on GPU with n/2 threads\n",
        "    max<<<1, n / 2>>>(arr_max);\n",
        "    cudaMemcpy(&result_max, arr_max, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cout << \"\\nThe maximum element is \" << result_max << endl;\n",
        "\n",
        "    //Calculating minimum number in array arr\n",
        "    float *arr_min, result_min;\n",
        "    cudaMalloc(&arr_min, size);\n",
        "    cudaMemcpy(arr_min, arr, size, cudaMemcpyHostToDevice);\n",
        "    //Launch min kernel on GPU with n/2 threads\n",
        "    min<<<1, n / 2>>>(arr_min);\n",
        "    cudaMemcpy(&result_min, arr_min, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cout << \"The minimum element is \" << result_min << endl;\n",
        "\n",
        "    //Calculating sum of all numbers in array arr\n",
        "    float *arr_sum, result_sum;\n",
        "    cudaMalloc(&arr_sum, size);\n",
        "    cudaMemcpy(arr_sum, arr, size, cudaMemcpyHostToDevice);\n",
        "    //Launch sum kernel on GPU with n/2 threads\n",
        "    sum<<<1, n / 2>>>(arr_sum);\n",
        "    cudaMemcpy(&result_sum, arr_sum, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cout << \"The sum of elements is \" << result_sum << endl;\n",
        "\n",
        "    //Calculating average of numbers in array arr\n",
        "    float *arr_avg, result_avg;\n",
        "    cudaMalloc(&arr_avg, size);\n",
        "    cudaMemcpy(arr_avg, arr, size, cudaMemcpyHostToDevice);\n",
        "    //Launch avg kernel on GPU with n/2 threads\n",
        "    avg<<<1, n / 2>>>(arr_avg);\n",
        "    cudaMemcpy(&result_avg, arr_avg, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    cout << \"The average of elements is \" << result_avg << endl;\n",
        "\n",
        "    //Calculating standard deviation of numbers in array arr\n",
        "    float *arr_sd, result_variance, result_sd;\n",
        "    cudaMalloc(&arr_sd, size);\n",
        "    cudaMemcpy(arr_sd, arr, size, cudaMemcpyHostToDevice);\n",
        "    mean_diff_sq<<<1, n>>>(arr_sd, result_avg);\n",
        "    sum<<<1, n / 2>>>(arr_sd);\n",
        "    cudaMemcpy(&result_variance, arr_sd, sizeof(float), cudaMemcpyDeviceToHost);\n",
        "    result_variance = result_variance / n;\n",
        "    result_sd = sqrt(result_variance);\n",
        "    cout << \"The standard deviation of elements is \" << result_sd << endl;\n",
        "\n",
        "    cudaFree(arr_min);\n",
        "    cudaFree(arr_sum);\n",
        "    cudaFree(arr_max);\n",
        "    cudaFree(arr_avg);\n",
        "    cudaFree(arr_sd);\n",
        "    return 0;\n",
        "}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "2_HPC_1_B.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
